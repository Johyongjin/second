# -*- coding: utf-8 -*-
"""1210_VAR_ì‹œë²”.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AGKPbt95m1WEkhfoh9UtWQj1ApW2Lhbj

**df_var_1209.csvë¥¼ ë¶ˆëŸ¬ì™€ì„œ VARë¥¼ ì‹¤ì‹œí•˜ê³ ì í•¨**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

path = "/content/drive/MyDrive/Aiffelthon/df_var_1209.csv"
df_var = pd.read_csv(path)

df_var.head()

df_var.info()

df_var.isna().sum()

#time ì¹¼ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
df_var['time'] = pd.to_datetime(df_var['time'])
df_var = df_var.set_index('time')

# VARì— ë“¤ì–´ê°ˆ ë³€ìˆ˜ subset ë§Œë“¤ê¸°

var_cols = [
    'ret_log_1d',
    'oi_close_diff',
    'funding_close',
    'liq_total_usd_diff',
    'taker_buy_ratio',
    'sth_sopr',
    'lth_sopr',
    'sth_realized_price_usd_diff',
    'lth_realized_price_usd_diff',
    'rhodl_ratio',
    'global_m2_yoy_diff',
    'sp500_ret',
    'nasdaq_ret',
    'etf_aum_diff'
]

df_var_sub = df_var[var_cols]

from statsmodels.tsa.stattools import adfuller

for col in df_var_sub.columns:
    p = adfuller(df_var_sub[col])[1]
    print(f'{col} â†’ p-value = {p:.4f}')

var_cols_final = [
    'ret_log_1d',
    'oi_close_diff',
    'funding_close',
    'liq_total_usd_diff',
    'taker_buy_ratio',
    'sth_sopr',
    'lth_sopr',
    'sth_realized_price_usd_diff',
    'lth_realized_price_usd_diff',
    'global_m2_yoy_diff',
    'sp500_ret',
    'nasdaq_ret',
    'etf_aum_diff'
]

from statsmodels.tsa.api import VAR

model = VAR(df_var[var_cols_final])
lag_selection = model.select_order(maxlags=10)
print(lag_selection.summary())

# 1. ì¸ë±ìŠ¤ê°€ timeì´ê³ , ì¼ë‹¨ìœ„ ì‹œê³„ì—´ì„ì„ ëª…ì‹œ (ì„ íƒì´ì§€ë§Œ ì¶”ì²œ)
df_var = df_var.asfreq('D')

# 2. VARì— ì“¸ ìµœì¢… ì»¬ëŸ¼ë§Œ ì„ íƒ
var_cols_final = [
    'ret_log_1d',
    'oi_close_diff',
    'funding_close',
    'liq_total_usd_diff',
    'taker_buy_ratio',
    'sth_sopr',
    'lth_sopr',
    'sth_realized_price_usd_diff',
    'lth_realized_price_usd_diff',
    'global_m2_yoy_diff',
    'sp500_ret',
    'nasdaq_ret',
    'etf_aum_diff'
]

df_var_final = df_var[var_cols_final]

from statsmodels.tsa.api import VAR

model = VAR(df_var_final)
var_result = model.fit(1)  # lag = 1
print(var_result.summary())

from statsmodels.tsa.stattools import grangercausalitytests

target = 'ret_log_1d'
variables = ['oi_close_diff', 'liq_total_usd_diff', 'taker_buy_ratio', 'etf_aum_diff']

for var in variables:
    print(f"\n### Testing whether {var} Granger-causes {target}")
    grangercausalitytests(df_var_final[[target, var]], maxlag=1, verbose=True)

import matplotlib.pyplot as plt

# 1. IRF ê°ì²´ ìƒì„± (ì˜ˆ: 10ì¼ ë°˜ì‘)
irf = var_result.irf(10)  # horizon=10ì¼

# 2. ì „ì²´ ë³€ìˆ˜ ê°„ IRF í”Œë¡¯
irf.plot(orth=False)
plt.show()

import matplotlib.pyplot as plt

irf = var_result.irf(10)  # 10ì¼ ê¸°ì¤€

fig = irf.plot(impulse='oi_close_diff', response='ret_log_1d', orth=False)
plt.title('IRF: oi_close_diff shock â†’ ret_log_1d')
plt.show()

fig = irf.plot(impulse='liq_total_usd_diff', response='ret_log_1d', orth=False)
plt.title('IRF: liq_total_usd_diff shock â†’ ret_log_1d')
plt.show()

fig = irf.plot(impulse='taker_buy_ratio', response='ret_log_1d', orth=False)
plt.title('IRF: taker_buy_ratio shock â†’ ret_log_1d')
plt.show()

fig = irf.plot(impulse='etf_aum_diff', response='ret_log_1d', orth=False)
plt.title('IRF: etf_aum_diff shock â†’ ret_log_1d')
plt.show()

irf_values = irf.irfs  # shape: (horizon+1, n_vars, n_vars)
irf_values.shape

var_names = var_result.names
print(var_names)

# impulse='liq_total_usd_diff', response='ret_log_1d' ì¸ë±ìŠ¤ ì°¾ê¸°
i_response = var_names.index('ret_log_1d')
i_impulse = var_names.index('liq_total_usd_diff')

# 0~10ì¼ ë°˜ì‘ ìˆ˜ì¹˜
irf_liq_to_ret = irf_values[:, i_response, i_impulse]
print(irf_liq_to_ret)

import numpy as np
import pandas as pd

# 10ì¼ horizonìœ¼ë¡œ IRF ê³„ì‚°
irf = var_result.irf(10)
irf_values = irf.irfs          # shape: (horizon+1, n_eq, n_shock)
var_names = var_result.names   # VARì— ë“¤ì–´ê°„ ë³€ìˆ˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
print(var_names)

# í˜„ì‹¤ì ì¸ shock í¬ê¸°ë“¤
liq_shocks = [1e8, 5e8, 1e9]          # 1ì–µ, 5ì–µ, 10ì–µ ë‹¬ëŸ¬
taker_shocks = [0.01, 0.05, 0.10]     # +1%, +5%, +10% í¬ì¸íŠ¸
etf_shocks = [1e8, 5e8, 1e9]          # 1ì–µ, 5ì–µ, 10ì–µ ë‹¬ëŸ¬

# ë³´ê³  ì‹¶ì€ horizon (ì¼)
horizons = [1, 3, 5, 10]              # 1ì¼, 3ì¼, 5ì¼, 10ì¼

def scaled_irf_table(
    irf_values,
    var_names,
    response_name,
    impulse_name,
    shock_list,
    horizons,
    label_prefix
):
    """
    response_name: 'ret_log_1d'
    impulse_name : 'liq_total_usd_diff' ë“±
    shock_list   : í˜„ì‹¤ shock í¬ê¸° ë¦¬ìŠ¤íŠ¸
    horizons     : [1,3,5,10] ê°™ì´ ë³´ê³  ì‹¶ì€ ì¼ìˆ˜
    label_prefix : 'liq', 'taker', 'etf' ë“±
    """
    i_resp = var_names.index(response_name)
    i_imp  = var_names.index(impulse_name)

    rows = []
    for s in shock_list:
        row = {}
        for h in horizons:
            # statsmodels: index 0 = 1-step ahead
            irf_h = irf_values[h-1, i_resp, i_imp]   # 1ë‹¨ìœ„ shock ê¸°ì¤€ log return ë³€í™”
            # í˜„ì‹¤ shock scale ì ìš© í›„, % ë‹¨ìœ„ ìˆ˜ìµë¥ ë¡œ ë³€í™˜
            delta_pct = irf_h * s * 100.0
            row[f'h={h}d'] = delta_pct
        rows.append(pd.Series(row, name=f'{label_prefix}_shock={s: .2e}'))

    return pd.DataFrame(rows)

# 1) ì²­ì‚° shock â†’ ret_log_1d
fe_irf_liq = scaled_irf_table(
    irf_values,
    var_names,
    response_name='ret_log_1d',
    impulse_name='liq_total_usd_diff',
    shock_list=liq_shocks,
    horizons=horizons,
    label_prefix='liq'
)

# 2) Taker Buy Ratio shock â†’ ret_log_1d
fe_irf_taker = scaled_irf_table(
    irf_values,
    var_names,
    response_name='ret_log_1d',
    impulse_name='taker_buy_ratio',
    shock_list=taker_shocks,
    horizons=horizons,
    label_prefix='taker'
)

# 3) ETF AUM shock â†’ ret_log_1d
fe_irf_etf = scaled_irf_table(
    irf_values,
    var_names,
    response_name='ret_log_1d',
    impulse_name='etf_aum_diff',
    shock_list=etf_shocks,
    horizons=horizons,
    label_prefix='etf'
)

fe_irf_liq, fe_irf_taker, fe_irf_etf

# ì„¸ í…Œì´ë¸”ì„ í•˜ë‚˜ë¡œ ë¶™ì´ê³  ë³´ê¸° ì¢‹ê²Œ ë°˜ì˜¬ë¦¼
fe_irf_all = (
    pd.concat([fe_irf_liq, fe_irf_taker, fe_irf_etf])
      .round(4)   # %ë‹¨ìœ„ ì†Œìˆ˜ 4ìë¦¬
)

fe_irf_all

# h=1d ê¸°ì¤€ìœ¼ë¡œ ì˜í–¥ë ¥ í¬ê¸° ìˆœ ì •ë ¬
fe_irf_all.sort_values(by='h=1d', ascending=True)  # í•˜ë½ ì¶©ê²© í¬ê¸° ê¸°ì¤€

horizons = list(range(1, 11))   # 1~10ì¼ ì „ì²´

# ì²­ì‚° shock â†’ ret_log_1d
fe_irf_liq = scaled_irf_table(
    irf_values,
    var_names,
    response_name='ret_log_1d',
    impulse_name='liq_total_usd_diff',
    shock_list=liq_shocks,
    horizons=horizons,
    label_prefix='liq'
)

# Taker Buy Ratio shock â†’ ret_log_1d
fe_irf_taker = scaled_irf_table(
    irf_values,
    var_names,
    response_name='ret_log_1d',
    impulse_name='taker_buy_ratio',
    shock_list=taker_shocks,
    horizons=horizons,
    label_prefix='taker'
)

# ETF AUM shock â†’ ret_log_1d
fe_irf_etf = scaled_irf_table(
    irf_values,
    var_names,
    response_name='ret_log_1d',
    impulse_name='etf_aum_diff',
    shock_list=etf_shocks,
    horizons=horizons,
    label_prefix='etf'
)

# ì„¸ ê°œ ëª¨ë‘ ê²°í•©
fe_irf_all = (
    pd.concat([fe_irf_liq, fe_irf_taker, fe_irf_etf])
    .round(6)
)

fe_irf_all

import matplotlib.pyplot as plt

# horizon ê°’ ìë™ ìƒì„± (1~10ì¼)
horizons = list(range(1, 11))

# fe_irf_allì˜ row ì´ë¦„ì„ ìˆœíšŒí•˜ë©´ì„œ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
plt.figure(figsize=(12, 8))

for idx, row in fe_irf_all.iterrows():
    plt.plot(horizons, row.values, marker='o', label=idx)

plt.axhline(0, color='black', linewidth=1)
plt.title('IRF (shock scale)', fontsize=16)
plt.xlabel('Days after Shock', fontsize=13)
plt.ylabel('Price Impact (%)', fontsize=13)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.show()

print(fe_irf_all.index.tolist())

import matplotlib.pyplot as plt

# 1~10ì¼ horizon
horizons = list(range(1, 11))

# ğŸ”§ indexì—ì„œ 'liq_shock'ê°€ ë“¤ì–´ê°„ í–‰ë§Œ ì„ íƒ (axis=0ì´ ì¤‘ìš”!)
liq_rows = fe_irf_all.filter(like='liq_shock', axis=0)

plt.figure(figsize=(10,6))

for idx, row in liq_rows.iterrows():
    plt.plot(horizons, row.values, marker='o', label=idx)

plt.axhline(0, color='black', linewidth=1)
plt.title('Shock â†’ Price Impact (%)', fontsize=15)
plt.xlabel('Days', fontsize=12)
plt.ylabel('Impact (%)', fontsize=12)
plt.legend()
plt.grid(True)
plt.show()

taker_rows = fe_irf_all.filter(like='taker_shock', axis=0)

plt.figure(figsize=(10,6))
for idx, row in taker_rows.iterrows():
    plt.plot(horizons, row.values, marker='o', label=idx)

plt.axhline(0, color='black', linewidth=1)
plt.title('Taker Buy Ratio Shock â†’ Price Impact (%)', fontsize=15)
plt.xlabel('Days', fontsize=12)
plt.ylabel('Impact (%)', fontsize=12)
plt.legend()
plt.grid(True)
plt.show()

etf_rows = fe_irf_all.filter(like='etf_shock', axis=0)

plt.figure(figsize=(10,6))
for idx, row in etf_rows.iterrows():
    plt.plot(horizons, row.values, marker='o', label=idx)

plt.axhline(0, color='black', linewidth=1)
plt.title('ETF AUM Shock â†’ Price Impact (%)', fontsize=15)
plt.xlabel('Days', fontsize=12)
plt.ylabel('Impact (%)', fontsize=12)
plt.legend()
plt.grid(True)
plt.show()

fevd = var_result.fevd(10)
fevd.summary()

fevd = var_result.fevd(10)
print(fevd.summary())

fevd = var_result.fevd(10)

var_names = var_result.names
i_ret = var_names.index("ret_log_1d")

rows = []
for h in range(1, 11):
    contrib = fevd.decomp[h-1, i_ret, :] * 100
    rows.append(contrib)

fevd_ret = pd.DataFrame(rows,
                        index=range(1, 11),
                        columns=var_names).round(3)
fevd_ret.index.name = "horizon"
fevd_ret

import matplotlib.pyplot as plt
import seaborn as sns

# fevd_ret: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” FEVD ê²°ê³¼ DataFrame (horizon Ã— shocks)

plt.figure(figsize=(14, 8))

sns.heatmap(
    fevd_ret,
    annot=True,
    fmt=".1f",
    cmap="YlGnBu",
    cbar=True
)

plt.title("FEVD Heatmap for ret_log_1d (Horizon 1~10 Days)", fontsize=16)
plt.xlabel("Shock Variables", fontsize=12)
plt.ylabel("Horizon (Days)", fontsize=12)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np

# 1ï¸âƒ£ timeì´ ì»¬ëŸ¼ì¸ì§€ / ì¸ë±ìŠ¤ì¸ì§€ì— ë”°ë¼ ê¸°ì¤€ ë‚ ì§œ ì²˜ë¦¬
if 'time' in df_var.columns:
    df_var['time'] = pd.to_datetime(df_var['time'])
    df_var = df_var.sort_values('time')
    latest = df_var.iloc[-1]
    ref_date = latest['time'].date()
else:
    # timeì´ ì¸ë±ìŠ¤ë¡œ ì¡´ì¬í•˜ëŠ” ê²½ìš°
    if not isinstance(df_var.index, pd.DatetimeIndex):
        df_var.index = pd.to_datetime(df_var.index)
    df_var = df_var.sort_index()
    latest = df_var.iloc[-1]
    ref_date = df_var.index[-1].date()

# 2ï¸âƒ£ ì‹ í˜¸ë“± í•¨ìˆ˜ë“¤ ê·¸ëŒ€ë¡œ ì‚¬ìš©
def signal_oi(oi_diff):
    if oi_diff > 1_000_000_000:   # +10ì–µ ì´ìƒ ì¦ê°€
        return "ğŸ”´ HIGH (ë ˆë²„ë¦¬ì§€ ê³¼ì—´)"
    elif oi_diff > 300_000_000:   # +3ì–µ ~ 10ì–µ
        return "ğŸŸ¡ CAUTION (ë ˆë²„ë¦¬ì§€ ì¦ê°€)"
    else:
        return "ğŸŸ¢ NORMAL"

def signal_funding(funding):
    if abs(funding) > 0.0003:   # Â±0.03% ì´ìƒ
        return "ğŸ”´ HIGH (ê·¹ë‹¨ì  í€ë”©)"
    elif abs(funding) > 0.0001: # Â±0.01% ~ 0.03%
        return "ğŸŸ¡ CAUTION"
    else:
        return "ğŸŸ¢ NORMAL"

def signal_liq(liq_usd):
    liq_abs = abs(liq_usd)
    if liq_abs > 200_000_000:      # 2ì–µ ì´ìƒ
        return "ğŸ”´ HIGH (ëŒ€ê·œëª¨ ì²­ì‚°)"
    elif liq_abs > 50_000_000:     # 5ì²œë§Œ ~ 2ì–µ
        return "ğŸŸ¡ CAUTION (ì²­ì‚° í™•ëŒ€)"
    else:
        return "ğŸŸ¢ NORMAL"

def signal_taker(taker_ratio):
    if taker_ratio > 0.60 or taker_ratio < 0.40:
        return "ğŸ”´ HIGH (ë§¤ìˆ˜/ë§¤ë„ í•œìª½ ì ë¦¼)"
    elif taker_ratio > 0.55 or taker_ratio < 0.45:
        return "ğŸŸ¡ CAUTION (í¸í–¥ ì¡´ì¬)"
    else:
        return "ğŸŸ¢ NORMAL"

def signal_m2(m2_diff):
    if m2_diff < 0:
        return "ğŸ”´ TIGHT (ìœ ë™ì„± ì¶•ì†Œ)"
    elif m2_diff < 0.01:
        return "ğŸŸ¡ NEUTRAL"
    else:
        return "ğŸŸ¢ LOOSE (ìœ ë™ì„± í™•ëŒ€)"

# 3ï¸âƒ£ ê° ì‹ í˜¸ ê³„ì‚°
sig_oi   = signal_oi(latest['oi_close_diff'])
sig_fund = signal_funding(latest['funding_close'])
sig_liq  = signal_liq(latest['liq_total_usd_diff'])
sig_taker= signal_taker(latest['taker_buy_ratio'])
sig_m2   = signal_m2(latest['global_m2_yoy_diff'])

def score_from_signal(s):
    if s.startswith("ğŸ”´"):
        return 2
    elif s.startswith("ğŸŸ¡"):
        return 1
    else:
        return 0

total_score = sum([
    score_from_signal(sig_oi),
    score_from_signal(sig_fund),
    score_from_signal(sig_liq),
    score_from_signal(sig_taker),
    score_from_signal(sig_m2)
])

if total_score >= 6:
    overall = "ğŸ”´ HIGH RISK (ë‹¨ê¸° ë³€ë™ì„±Â·ì²­ì‚° ë¦¬ìŠ¤í¬ ë§¤ìš° í¼)"
elif total_score >= 3:
    overall = "ğŸŸ¡ CAUTION (í¬ì§€ì…˜ ê´€ë¦¬ í•„ìš”)"
else:
    overall = "ğŸŸ¢ NORMAL (êµ¬ì¡°ì  ê³¼ì—´ ì‹ í˜¸ ì•½í•¨)"

# 4ï¸âƒ£ ìµœì¢… ì¶œë ¥
print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print(f"  Bitcoin Risk Dashboard (ê¸°ì¤€ì¼: {ref_date})")
print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

print("[ ë ˆë²„ë¦¬ì§€ êµ¬ì¡° ]")
print(f"OI ë³€í™”ëŸ‰ (oi_close_diff):      {sig_oi}   (ê°’: {latest['oi_close_diff']:,.0f})")
print(f"Funding Rate (funding_close):   {sig_fund} (ê°’: {latest['funding_close']:.5f})")
print(f"Liquidation USD (liq_total):    {sig_liq}  (ê°’: {latest['liq_total_usd_diff']:,.0f})\n")

print("[ ì‹œì¥ íë¦„ (Flow) ]")
print(f"Taker Buy Ratio:                {sig_taker} (ê°’: {latest['taker_buy_ratio']:.3f})\n")

print("[ ê±°ì‹œ ìœ ë™ì„± ]")
print(f"Global M2 YoY Diff:             {sig_m2} (ê°’: {latest['global_m2_yoy_diff']:.3f})\n")

print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print(f"  ì¢…í•© ìœ„í—˜ë„: {overall}")
print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

# ğŸ”¹ ë°©ê¸ˆ ê³„ì‚°í•œ latest, sig_oi, sig_fund, sig_liq, sig_taker, sig_m2, overall ê·¸ëŒ€ë¡œ ì‚¬ìš©

def explain_oi(sig, val):
    if sig.startswith("ğŸ”´"):
        return (
            f"- ë ˆë²„ë¦¬ì§€ í¬ì§€ì…˜: {sig} / ìµœê·¼ OIê°€ {val:,.0f} USD ì¦ê°€í•´ "
            "ê³¼ê±° í‰ê·  ëŒ€ë¹„ ë ˆë²„ë¦¬ì§€ê°€ í¬ê²Œ ìŒ“ì¸ êµ¬ê°„ì…ë‹ˆë‹¤. "
            "ì‘ì€ ê°€ê²© ì¶©ê²©ì—ë„ ê°•í•œ ì²­ì‚°ì´ ì—°ì‡„ì ìœ¼ë¡œ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ìƒíƒœì…ë‹ˆë‹¤."
        )
    elif sig.startswith("ğŸŸ¡"):
        return (
            f"- ë ˆë²„ë¦¬ì§€ í¬ì§€ì…˜: {sig} / OIê°€ {val:,.0f} USD ì¦ê°€í•œ ìˆ˜ì¤€ìœ¼ë¡œ, "
            "ë ˆë²„ë¦¬ì§€ê°€ ì™„ë§Œíˆ ëŠ˜ì–´ë‚˜ë©° ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§„ ìƒí™©ì…ë‹ˆë‹¤. "
            "ë‹¤ë§Œ ì•„ì§ â€˜ê·¹ë‹¨ì  ê³¼ì—´â€™ ìˆ˜ì¤€ê¹Œì§€ëŠ” ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤."
        )
    else:
        return (
            f"- ë ˆë²„ë¦¬ì§€ í¬ì§€ì…˜: {sig} / OI ë³€í™”ê°€ {val:,.0f} USD ìˆ˜ì¤€ìœ¼ë¡œ, "
            "ë ˆë²„ë¦¬ì§€ê°€ ê³¼ê±° í‰ê·  ë˜ëŠ” ê·¸ ì´í•˜ë¡œ ì•ˆì •ëœ ìƒíƒœì…ë‹ˆë‹¤. "
            "ë ˆë²„ë¦¬ì§€ ì²­ì‚°ë°œ ê¸‰ë½ ìœ„í—˜ì€ ì œí•œì ì¸ í¸ì…ë‹ˆë‹¤."
        )

def explain_funding(sig, val):
    if sig.startswith("ğŸ”´"):
        return (
            f"- í€ë”© ë¹„ìœ¨: {sig} / Funding Rate â‰ˆ {val:.3%} ë¡œ, "
            "ë¡± í˜¹ì€ ìˆ í•œìª½ìœ¼ë¡œ í¬ì§€ì…˜ì´ ê³¼ë„í•˜ê²Œ ì ë¦° ìƒíƒœì…ë‹ˆë‹¤. "
            "ê³¼ê±° VAR/IRF ë¶„ì„ ê¸°ì¤€, ì´ëŸ° êµ¬ê°„ì—ì„œëŠ” ë‹¨ê¸°ì ìœ¼ë¡œ ë˜ëŒë¦¼ ë³€ë™ì„±ì´ ì»¤ì§€ëŠ” íŒ¨í„´ì´ ìì£¼ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    elif sig.startswith("ğŸŸ¡"):
        return (
            f"- í€ë”© ë¹„ìœ¨: {sig} / Funding Rate â‰ˆ {val:.3%} ìˆ˜ì¤€ìœ¼ë¡œ, "
            "í•œìª½ í¬ì§€ì…˜ì´ ìš°ì„¸í•˜ê¸´ í•˜ì§€ë§Œ ì•„ì§ ê·¹ë‹¨ì ì€ ì•„ë‹™ë‹ˆë‹¤. "
            "í˜„ì¬ ê°€ê²© ì›€ì§ì„ì€ â€˜í¬ì§€ì…˜ ì¡°ì • êµ¬ê°„â€™ì— ê°€ê¹ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    else:
        return (
            f"- í€ë”© ë¹„ìœ¨: {sig} / Funding Rate â‰ˆ {val:.3%} ë¡œ, "
            "ë¡±Â·ìˆ ê· í˜•ì´ ë¹„êµì  ì˜ ë§ëŠ” ìƒíƒœì…ë‹ˆë‹¤. "
            "ê°€ê²© ê¸‰ë“±Â·ê¸‰ë½ì´ ë‚˜ì™€ë„ ë ˆë²„ë¦¬ì§€ í¬ì§€ì…˜ì´ ì¶”ê°€ë¡œ ë¶€ì±„ì§ˆí•  ê°€ëŠ¥ì„±ì€ í¬ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )

def explain_liq(sig, val):
    if sig.startswith("ğŸ”´"):
        return (
            f"- ì²­ì‚° ê·œëª¨: {sig} / ì¼ê°„ ì²­ì‚° ê·œëª¨ê°€ ì•½ {abs(val):,.0f} USD ë¡œ, "
            "ì§ì ‘ì ì¸ ê°•ì œ ì²­ì‚°ì´ ê°€ê²© ë³€ë™ì„ ì£¼ë„í•œ ë‚ ì— ê°€ê¹ìŠµë‹ˆë‹¤. "
            "ì´ ê²½ìš° ê°€ê²© ê¸‰ë½ì€ í€ë”ë©˜í„¸ë³´ë‹¤ëŠ” ë ˆë²„ë¦¬ì§€ êµ¬ì¡° í•´ì†Œ ì„±ê²©ì´ ê°•í•©ë‹ˆë‹¤."
        )
    elif sig.startswith("ğŸŸ¡"):
        return (
            f"- ì²­ì‚° ê·œëª¨: {sig} / ì²­ì‚° ê·œëª¨ê°€ ì•½ {abs(val):,.0f} USD ë¡œ, "
            "ê°•ì œ ì²­ì‚°ì´ ì ì§„ì ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. "
            "ì¶”ê°€ ë³€ë™ì„±ì— ëŒ€ë¹„í•´ ë ˆë²„ë¦¬ì§€ ë¹„ì¤‘ì„ ì¤„ì´ëŠ” ê²ƒì´ ìœ ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    else:
        return (
            f"- ì²­ì‚° ê·œëª¨: {sig} / ì²­ì‚° ê·œëª¨ê°€ ì•½ {abs(val):,.0f} USD ë¡œ, "
            "ì§ì ‘ì ì¸ ë ˆë²„ë¦¬ì§€ ê°•ì œ ì²­ì‚°ì´ ì‹œì¥ì„ í”ë“œëŠ” ìˆ˜ì¤€ì€ ì•„ë‹™ë‹ˆë‹¤. "
            "ìµœê·¼ ì›€ì§ì„ì€ â€˜í¬ì§€ì…˜ ê°•ì œ ì •ë¦¬â€™ë³´ë‹¤ëŠ” ì‹¬ë¦¬Â·í˜„ë¬¼ ìˆ˜ê¸‰ì— ë” ê°€ê¹ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )

def explain_taker(sig, val):
    if sig.startswith("ğŸ”´"):
        return (
            f"- ë§¤ìˆ˜Â·ë§¤ë„ ì ë¦¼: {sig} / Taker Buy Ratio â‰ˆ {val:.3f} ë¡œ, "
            "ë‹¨ê¸°ì ìœ¼ë¡œ ë§¤ìˆ˜ ë˜ëŠ” ë§¤ë„ í•œìª½ ë°©í–¥ìœ¼ë¡œ ê±°ë˜ê°€ ê³¼ë„í•˜ê²Œ ì ë ¤ ìˆìŠµë‹ˆë‹¤. "
            "ì´ êµ¬ê°„ì—ì„œëŠ” ë°˜ëŒ€ ë°©í–¥ ìŠ¤íŒŒì´í¬(ìˆÂ·ë¡± ìŠ¤í€´ì¦ˆ)ê°€ ìì£¼ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    elif sig.startswith("ğŸŸ¡"):
        return (
            f"- ë§¤ìˆ˜Â·ë§¤ë„ ì ë¦¼: {sig} / Taker Buy Ratio â‰ˆ {val:.3f} ìœ¼ë¡œ, "
            "í•œìª½ ë°©í–¥ìœ¼ë¡œ ìš°ìœ„ê°€ ìˆì§€ë§Œ ì•„ì§ â€˜ê·¹ë‹¨ì  ê³µí¬/íƒìš•â€™ ë‹¨ê³„ëŠ” ì•„ë‹™ë‹ˆë‹¤. "
            "ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆì–´ ë ˆë²„ë¦¬ì§€ ê´€ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤."
        )
    else:
        return (
            f"- ë§¤ìˆ˜Â·ë§¤ë„ ì ë¦¼: {sig} / Taker Buy Ratio â‰ˆ {val:.3f} ìœ¼ë¡œ, "
            "ë§¤ìˆ˜Â·ë§¤ë„ íë¦„ì´ ë¹„êµì  ê· í˜• ì¡í˜€ ìˆìŠµë‹ˆë‹¤. "
            "ê°€ê²© ì›€ì§ì„ì´ íŠ¹ì • ë°©í–¥ìœ¼ë¡œ â€˜ëª°ë ¤ì„œâ€™ ë‚˜ì˜¤ëŠ” êµ­ë©´ì€ ì•„ë‹™ë‹ˆë‹¤."
        )

def explain_m2(sig, val):
    if sig.startswith("ğŸ”´"):
        return (
            f"- ê¸€ë¡œë²Œ ìœ ë™ì„±(M2): {sig} / ìµœê·¼ YoY Diff â‰ˆ {val:.3%} ìˆ˜ì¤€ìœ¼ë¡œ, "
            "ê±°ì‹œ ìœ ë™ì„±ì´ ì¶•ì†Œë˜ëŠ” í™˜ê²½ì…ë‹ˆë‹¤. "
            "ìœ„í—˜ìì‚° ì „ë°˜ì— â€˜ë¦¬ë ˆì´íŒ… í•˜ë½â€™ì´ ë™ë°˜ë  ê°€ëŠ¥ì„±ì„ ì—¼ë‘ì— ë‘˜ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
        )
    elif sig.startswith("ğŸŸ¡"):
        return (
            f"- ê¸€ë¡œë²Œ ìœ ë™ì„±(M2): {sig} / YoY Diff â‰ˆ {val:.3%} ìˆ˜ì¤€ìœ¼ë¡œ, "
            "ìœ ë™ì„± ì¸¡ë©´ì—ì„œ ëšœë ·í•œ íŒ½ì°½Â·ì¶•ì†Œ ì‹ í˜¸ê°€ ì•„ë‹Œ ì¤‘ë¦½ êµ¬ê°„ì…ë‹ˆë‹¤. "
            "í˜„ì¬ ë¹„íŠ¸ì½”ì¸ ë³€ë™ì€ ê±°ì‹œë³´ë‹¤ëŠ” â€˜ì‹œì¥ ë‚´ë¶€ êµ¬ì¡°(ë ˆë²„ë¦¬ì§€, ETF, ì˜¨ì²´ì¸)â€™ ì˜í–¥ì´ ë” í´ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
        )
    else:
        return (
            f"- ê¸€ë¡œë²Œ ìœ ë™ì„±(M2): {sig} / YoY Diff â‰ˆ {val:.3%} ìˆ˜ì¤€ìœ¼ë¡œ, "
            "ì™„ë§Œí•œ ìœ ë™ì„± í™•ëŒ€ êµ­ë©´ì— ê°€ê¹ìŠµë‹ˆë‹¤. "
            "ë‹¨ê¸° ì¡°ì •ì´ ìˆì–´ë„ ì¤‘ì¥ê¸° ê´€ì ì—ì„œëŠ” ìœ ë™ì„± í™˜ê²½ì´ ë’·ë°›ì¹¨ë˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤."
        )

def summarize_overall(overall_signal):
    if overall_signal.startswith("ğŸ”´"):
        return (
            "â–¶ ì¢…í•© í•´ì„: ë ˆë²„ë¦¬ì§€Â·í€ë”©Â·ì²­ì‚°Â·ìœ ë™ì„± ì‹ í˜¸ê°€ ë™ì‹œì— ì•…í™”ëœ **ê³ ìœ„í—˜ êµ¬ê°„**ì…ë‹ˆë‹¤.\n"
            "  - ê³¼ê±° VAR/IRF ë¶„ì„ ê¸°ì¤€, ì´ëŸ° ì‹œê¸°ì—ëŠ” ë‹¨ê¸° ê¸‰ë½/ê¸‰ë“± ìŠ¤íŒŒì´í¬ê°€ ë°˜ë³µë˜ëŠ” ê²½í–¥ì´ ê°•í–ˆìŠµë‹ˆë‹¤.\n"
            "  - ì´ êµ¬ê°„ì—ì„œì˜ â€˜ì¶”ê²© ë§¤ìˆ˜/ì¶”ê²© ë§¤ë„â€™ëŠ” ì†ì‹¤ í™•ëŒ€ë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n"
            "  - ì „ëµ: ë ˆë²„ë¦¬ì§€ ì¶•ì†Œ, ì†ì ˆ í­ ì¶•ì†Œ, í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€ ë“± **ë¦¬ìŠ¤í¬ ê´€ë¦¬ ìš°ì„ **ì´ í•©ë¦¬ì ì…ë‹ˆë‹¤."
        )
    elif overall_signal.startswith("ğŸŸ¡"):
        return (
            "â–¶ ì¢…í•© í•´ì„: ì¼ë¶€ ë ˆë²„ë¦¬ì§€Â·í€ë”© ì§€í‘œê°€ ê³¼ì—´ ë˜ëŠ” ì¼ì‹œì  ì ë¦¼ì„ ë³´ì´ëŠ” **ì£¼ì˜ êµ¬ê°„**ì…ë‹ˆë‹¤.\n"
            "  - í˜„ì¬ ì¡°ì •ì€ êµ¬ì¡°ì  ë¶•ê´´ë¼ê¸°ë³´ë‹¤, ë ˆë²„ë¦¬ì§€ í¬ì§€ì…˜ ì¡°ì •ê³¼ ë‹¨ê¸° ì‹¬ë¦¬ ìš”ì¸ì´ ì„ì¸ êµ­ë©´ì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.\n"
            "  - ê³¼ê±° ìœ ì‚¬ êµ¬ê°„ì—ì„œëŠ” ìˆ˜ ì¼~ìˆ˜ ì£¼ ë‚´ì— ë˜ëŒë¦¼ì´ ìì£¼ ê´€ì°°ë˜ì—ˆê³ , â€˜íŒ¨ë‹‰ì…€â€™ë³´ë‹¤ëŠ” í¬ì§€ì…˜ ì¬ì¡°ì •ì´ ìœ ë¦¬í–ˆìŠµë‹ˆë‹¤.\n"
            "  - ì „ëµ: ë°©í–¥ì„± ë„ë°•ë³´ë‹¤ëŠ” ë ˆë²„ë¦¬ì§€ ê´€ë¦¬, ë¶„í•  ì ‘ê·¼, ì†ìµë¹„ê°€ ë§ëŠ” êµ¬ê°„ì—ì„œì˜ ì œí•œì  ëŒ€ì‘ì´ ì í•©í•©ë‹ˆë‹¤."
        )
    else:
        return (
            "â–¶ ì¢…í•© í•´ì„: ë ˆë²„ë¦¬ì§€Â·ì²­ì‚°Â·ìœ ë™ì„± ëª¨ë‘ì—ì„œ **ê³¼ì—´ ì‹ í˜¸ê°€ ê°•í•˜ì§€ ì•Šì€ ì •ìƒ êµ¬ê°„**ì…ë‹ˆë‹¤.\n"
            "  - ë‹¨ê¸° ì¡°ì •ì´ ìˆë”ë¼ë„ êµ¬ì¡°ì  ë ˆë²„ë¦¬ì§€ ì²­ì‚°ì´ë‚˜ ë§¤í¬ë¡œ ì‡¼í¬ê°€ ì£¼ëœ ì›ì¸ì¼ ê°€ëŠ¥ì„±ì€ ë‚®ìŠµë‹ˆë‹¤.\n"
            "  - ì¥ê¸° ë³´ìœ ì ì…ì¥ì—ì„œëŠ” â€˜êµ¬ì¡°ì  ë¦¬ìŠ¤í¬ë³´ë‹¤ëŠ” ë…¸ì´ì¦ˆì— ê°€ê¹Œìš´ ë³€ë™â€™ìœ¼ë¡œ ë³¼ ì—¬ì§€ê°€ í½ë‹ˆë‹¤.\n"
            "  - ì „ëµ: íŒ¨ë‹‰ì…€ë³´ë‹¤ëŠ”, ë³¸ì¸ì˜ íˆ¬ì ê¸°ê°„Â·ë¦¬ìŠ¤í¬ í—ˆìš©ë„ì— ë§ëŠ” **ê³„íšëœ ë¦¬ë°¸ëŸ°ì‹±**ì´ í•µì‹¬ì…ë‹ˆë‹¤."
        )

# ğŸ”» ì‹¤ì œ ë¬¸ì¥ ìƒì„±
lines = []

lines.append(f"[1] ì˜¤ëŠ˜ ê¸°ì¤€ ìš”ì•½ (ê¸°ì¤€ì¼: {ref_date})")
lines.append(f"  â†’ ì¢…í•© ìœ„í—˜ë„: {overall}")
lines.append("")

lines.append("[2] ë ˆë²„ë¦¬ì§€Â·ì„ ë¬¼ êµ¬ì¡° í•´ì„")
lines.append("  " + explain_oi(sig_oi,   latest['oi_close_diff']))
lines.append("  " + explain_funding(sig_fund, latest['funding_close']))
lines.append("  " + explain_liq(sig_liq, latest['liq_total_usd_diff']))
lines.append("")

lines.append("[3] í˜„ë¬¼Â·ì‹¬ë¦¬ ë° ìœ ë™ì„± í™˜ê²½")
lines.append("  " + explain_taker(sig_taker, latest['taker_buy_ratio']))
lines.append("  " + explain_m2(sig_m2, latest['global_m2_yoy_diff']))
lines.append("")

lines.append("[4] íˆ¬ì í–‰ë™ ê´€ì  ì •ë¦¬")
lines.append("  " + summarize_overall(overall))

dashboard_text = "\n".join(lines)
print(dashboard_text)

import numpy as np

# 1) horizon ì •ì˜ (1~10ì¼)
horizons = list(range(1, fe_irf_all.shape[1] + 1))

def summarize_shock(row, horizons):
    """
    row: fe_irf_allì˜ í•œ í–‰ (ì˜ˆ: 'liq_shock= 1.00e+09')
    -> ìµœëŒ€ ì˜í–¥ ì‹œì , íšŒë³µ ì‹œì (80% ì´ìƒ ê°ì†Œ), 10ì¼ ëˆ„ì  ì˜í–¥ ê³„ì‚°
    """
    impacts = row.values.astype(float)

    # ì „ë¶€ 0ì´ë©´ None
    max_abs = np.max(np.abs(impacts))
    if max_abs == 0:
        return None

    # í”¼í¬(ìµœëŒ€ ì ˆëŒ€ê°’) ì‹œì 
    peak_idx = int(np.argmax(np.abs(impacts)))
    peak_day = horizons[peak_idx]
    peak_val = impacts[peak_idx]  # % ë‹¨ìœ„ (ì´ë¯¸ fe_irf_allì´ %ë¼ê³  ê°€ì •)

    # 'ì¶©ê²©ì˜ 80% ì´ìƒ í¡ìˆ˜' ê¸°ì¤€ (í”¼í¬ì˜ 20% ì´í•˜ê°€ ë˜ëŠ” ì²« ë‚ )
    threshold = 0.2 * max_abs
    recovery_day = None
    for h, imp in zip(horizons, impacts):
        if abs(imp) <= threshold:
            recovery_day = h
            break

    # 10ì¼ ëˆ„ì  ì˜í–¥ (%í¬ì¸íŠ¸ í•©)
    cum_10d = impacts.sum()

    return {
        "peak_day": peak_day,
        "peak_impact": peak_val,
        "recovery_day": recovery_day,
        "cum_10d": cum_10d,
    }

# 2) ìš°ë¦¬ê°€ ë³´ê³  ì‹¶ì€ ëŒ€í‘œ ì‡¼í¬ 3ê°œ ì„ íƒ
row_liq   = fe_irf_all.loc['liq_shock= 1.00e+09']     # 10ì–µ ë‹¬ëŸ¬ ì²­ì‚°
row_taker = fe_irf_all.loc['taker_shock= 1.00e-01']   # Taker Buy Ratio +0.10
row_etf   = fe_irf_all.loc['etf_shock= 1.00e+09']     # ETF AUM +10ì–µ ë‹¬ëŸ¬

summary_liq   = summarize_shock(row_liq, horizons)
summary_taker = summarize_shock(row_taker, horizons)
summary_etf   = summarize_shock(row_etf, horizons)

summary_liq, summary_taker, summary_etf

def line_for_liq(meta):
    if meta is None:
        return "- ì²­ì‚° ì‡¼í¬: ê³¼ê±° ë°ì´í„°ì—ì„œ ìœ ì˜ë¯¸í•œ ê°€ê²© ë°˜ì‘ì´ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    return (
        f"- ëŒ€ê·œëª¨ ì²­ì‚° ì‡¼í¬ (â‰ˆ 10ì–µ ë‹¬ëŸ¬ ê°•ì œì²­ì‚° ê°€ì •): "
        f"{meta['peak_day']}ì¼ì°¨ì— ìµœëŒ€ {meta['peak_impact']:.1f}% ë³€ë™ì´ ë‚˜íƒ€ë‚¬ê³ , "
        f"ëŒ€ëµ {meta['recovery_day']}ì¼ ì´ë‚´ì— ì¶©ê²©ì˜ ëŒ€ë¶€ë¶„(ì•½ 80% ì´ìƒ)ì´ í¡ìˆ˜ë˜ëŠ” íŒ¨í„´ì´ì—ˆìŠµë‹ˆë‹¤. "
        f"(10ì¼ ëˆ„ì  ì˜í–¥ â‰ˆ {meta['cum_10d']:.1f}%p)"
    )

def line_for_taker(meta):
    if meta is None:
        return "- Taker ì ë¦¼ ì‡¼í¬: ê³¼ê±° ë°ì´í„°ì—ì„œ ìœ ì˜ë¯¸í•œ ê°€ê²© ë°˜ì‘ì´ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    return (
        f"- Taker Buy Ratio ì‡¼í¬ (+0.10p ê°€ì •): "
        f"{meta['peak_day']}ì¼ì°¨ì— ìµœëŒ€ {meta['peak_impact']:.2f}% ì˜í–¥ì´ ê´€ì°°ë˜ì—ˆê³ , "
        f"{meta['recovery_day']}ì¼ ë‚´ì— ëŒ€ë¶€ë¶„ì´ í•´ì†Œë˜ì—ˆìŠµë‹ˆë‹¤. "
        f"(10ì¼ ëˆ„ì  ì˜í–¥ â‰ˆ {meta['cum_10d']:.2f}%p, ë°©í–¥ì„±ë³´ë‹¤ëŠ” ë‹¨ê¸° ë…¸ì´ì¦ˆì— ê°€ê¹Œìš´ ê·œëª¨)"
    )

def line_for_etf(meta):
    if meta is None:
        return "- ETF AUM ì‡¼í¬: ê³¼ê±° ë°ì´í„°ì—ì„œ ìœ ì˜ë¯¸í•œ ê°€ê²© ë°˜ì‘ì´ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    return (
        f"- ETF AUM ì‡¼í¬ (ìê¸ˆ ìœ ì… +10ì–µ ë‹¬ëŸ¬ ê°€ì •): "
        f"{meta['peak_day']}ì¼ì°¨ì— ìµœëŒ€ {meta['peak_impact']:.2f}%ì˜ ì™„ë§Œí•œ ì–‘(+)ì˜ ë°˜ì‘ì´ ë‚˜íƒ€ë‚¬ê³ , "
        f"ëŒ€ëµ {meta['recovery_day']}ì¼ ì´ë‚´ì— ì¶”ê°€ íš¨ê³¼ëŠ” ì œí•œì ì¸ ìˆ˜ì¤€ìœ¼ë¡œ ì¤„ì—ˆìŠµë‹ˆë‹¤. "
        f"(10ì¼ ëˆ„ì  ì˜í–¥ â‰ˆ {meta['cum_10d']:.2f}%p)"
    )

liq_line   = line_for_liq(summary_liq)
taker_line = line_for_taker(summary_taker)
etf_line   = line_for_etf(summary_etf)

print(liq_line)
print(taker_line)
print(etf_line)

lines = dashboard_text.split("\n")  # ê¸°ì¡´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ìª¼ê°œê³ 

lines.append("")
lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
lines.append("  ê³¼ê±° ì¶©ê²© í¡ìˆ˜ ì†ë„ (IRF ê¸°ë°˜ ìš”ì•½)")
lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
lines.append(liq_line)
lines.append(taker_line)
lines.append(etf_line)

dashboard_text_extended = "\n".join(lines)
print(dashboard_text_extended)

